[{"authors":["admin"],"categories":null,"content":"I’m Sebastián Ferrada, a postdoctoral researcher at the Department of Computer Science (IDA) at Linköping University. I obtained my PhD from Universidad de Chile with my thesis “Similarity-based Web Queries”. My research interests include Federated Database Systems, Multimedia Databases and Linked Data. I’m currently researching the interoperability between heterogeneous graph databases.\nBesides research I really enjoy teaching. I’m currently teaching the Advanced Databases course and I’m a lab assistant at the Relational Database course, both from IDA.\n","date":1540835003,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1540835003,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://www.sferrada.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I’m Sebastián Ferrada, a postdoctoral researcher at the Department of Computer Science (IDA) at Linköping University. I obtained my PhD from Universidad de Chile with my thesis “Similarity-based Web Queries”. My research interests include Federated Database Systems, Multimedia Databases and Linked Data.","tags":null,"title":"Sebastián Ferrada Aliaga","type":"authors"},{"authors":[],"categories":null,"content":"","date":1618930800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618930800,"objectID":"4a4fe00aa595ca7a0615c8a6bea4243a","permalink":"http://www.sferrada.com/talk/similarity-based-sparql-operators/","publishdate":"2021-04-19T22:11:25-04:00","relpermalink":"/talk/similarity-based-sparql-operators/","section":"talk","summary":"In this talk we present two similarity-based operators to extend SPARQL: the similarity join and clustering. We provide syntax and semantics, as well as an open inplementation. We present use-case queries and compare our implementation with other similar systems and provide evidence that our proposal outperforms them in terms of execution time and scalability.","tags":[],"title":"Similarity-based SPARQL Operators","type":"talk"},{"authors":["Sebastián Ferrada","Benjamin Bustos","Aidan Hogan"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"526031fc432bb3019cb8debc2d0c65e5","permalink":"http://www.sferrada.com/publication/ferrada-simjoins-2020/","publishdate":"2020-08-01T00:00:00Z","relpermalink":"/publication/ferrada-simjoins-2020/","section":"publication","summary":"We propose techniques that support the efficient computation of multidimensional similarity joins in an RDF/SPARQL setting, where similarity in an RDF graph is measured with respect to a set of attributes selected in the SPARQL query. While similarity joins have been studied in other contexts, RDF graphs present unique challenges. We discuss how a similarity join operator can be included in the SPARQL language, and investigate ways in which it can be implemented and optimised. We devise experiments to compare three similarity join algorithms over two datasets. Our results reveal that our techniques outperform DBSimJoin: a PostgreSQL extension that supports similarity joins.","tags":["SPARQL","Similarity Joins","Wikidata"],"title":"Extending SPARQL with Similarity Joins","type":"publication"},{"authors":["Sebastián Ferrada","Benjamin Bustos","Nora Reyes"],"categories":null,"content":"","date":1582502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582502400,"objectID":"457305eceaf0c98484f7b17b865991f9","permalink":"http://www.sferrada.com/publication/ferrada-simple-2020/","publishdate":"2020-02-24T00:00:00Z","relpermalink":"/publication/ferrada-simple-2020/","section":"publication","summary":"Similarity join is a key operation in metric databases. It retrieves all pairs of elements that are similar. Solving such a problem usually requires comparing every pair of objects of the datasets, even when indexing and ad hoc algorithms are used. We propose a simple and efficient algorithm for the computation of the approximated k nearest neighbor self-similarity join. This algorithm computes $\\Theta(3/2)$ distances and it is empirically shown that it reaches an empirical precision of 46% in real-world datasets. We provide a comparison to other common techniques such as Quickjoin and Locality-Sensitive Hashing and argue that our proposal has a better execution time and average precision.","tags":null,"title":"An Efficient Algorithm for Approximated Self-similarity Joins in Metric Spaces","type":"publication"},{"authors":null,"categories":null,"content":"","date":1581433200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581433200,"objectID":"c125a3bca93caec0c8c8ae8888b993be","permalink":"http://www.sferrada.com/talk/iswc2020/","publishdate":"2020-02-11T15:00:00Z","relpermalink":"/talk/iswc2020/","section":"talk","summary":"RDF datasets are often made accessible over the Web through a SPARQL endpoint where users typically write queries requesting matches on the content. For instance, in Wikidata, a SPARQL query may request 'the names and nationalities of laureates of the Nobel Prize in Literature that have fought in a war'. However, there are times when an exact match is not what users need; instead they wish to write a similarity query, for which there is no declarative support in the SPARQL standard. Hence a query to obtain 'the Latin American country with the most similar population and GDP to Italy cannot be written declaratively in SPARQL; even if the query were expressed with distances defined using low-level numeric operators, the SPARQL engine is unlikely to know how to optimise such a query, resorting to brute-force evaluation. On the other hand, the potential applications for similarity queries in SPARQL are numerous, including: entity comparison and linking, multimedia retrieval, similarity graphs, pattern recognition, data integration, as well as domain use-cases, such as protein similarity computation. In this talk, we motivate similarity-based queries for SPARQL and present a system for executing such queries over RDF graphs and integrating them with SPARQL including syntax discussion, query planning and optimisation, and novel use-cases.","tags":["Similarity Joins","SPARQL","Web Image Retrieval","Semantic Web"],"title":"Extending  SPARQL with Similarity Joins","type":"talk"},{"authors":null,"categories":null,"content":"","date":1580990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580990400,"objectID":"cd0c98f8a192b38112a18578e187f026","permalink":"http://www.sferrada.com/talk/insight-visit-20/","publishdate":"2020-02-06T12:00:00Z","relpermalink":"/talk/insight-visit-20/","section":"talk","summary":"RDF datasets are often made accessible over the Web through a SPARQL endpoint where users typically write queries requesting matches on the content. For instance, in Wikidata, a SPARQL query may request 'the names and nationalities of laureates of the Nobel Prize in Literature that have fought in a war'. However, there are times when an exact match is not what users need; instead they wish to write a similarity query, for which there is no declarative support in the SPARQL standard. Hence a query to obtain 'the Latin American country with the most similar population and GDP to Italy cannot be written declaratively in SPARQL; even if the query were expressed with distances defined using low-level numeric operators, the SPARQL engine is unlikely to know how to optimise such a query, resorting to brute-force evaluation. On the other hand, the potential applications for similarity queries in SPARQL are numerous, including: entity comparison and linking, multimedia retrieval, similarity graphs, pattern recognition, data integration, as well as domain use-cases, such as protein similarity computation. In this talk, we motivate similarity-based queries for SPARQL and present a system for executing such queries over RDF graphs and integrating them with SPARQL including syntax discussion, query planning and optimisation, and novel use-cases.","tags":["Similarity Joins","SPARQL","Web Image Retrieval","Semantic Web"],"title":"Similarity Joins in SPARQL","type":"talk"},{"authors":["Sebastián Ferrada Aliaga"],"categories":null,"content":"Al diseñar las relaciones que deben formar parte de un esquema relacional de bases de datos hay ciertos aspectos que se deben considerar de forma que se asegure que al agregar los datos en el esquema estos no presenten anomalías. En este artículo, voy a discutir distintas anomalías que pueden presentarse en esquemas relacionales y cómo pueden ser erradicados utilizando formas normales. Las formas normales son condiciones que todas las tablas de un esquema deben cumplir para así garantizar ciertas propiedades deseables. Las formas normales fueron propuestas principalmente por Edgar F. Codd durante los 70s.\nPara entender de mejor forma las condiciones que se requieren en cada forma normal, es recomendable que conozcas lo que es una llave y una dependencia funcional en el modelo relacional. En este post puedes encontrar definiciones y ejemplos también.\nVamos a guiar la explicación a través de una base de datos que mantiene el registro de los Pokémon que son capturados por los distintos entrenadores. En la Tabla 1, se muestra una forma sobre cómo organizar nuestros datos. La tabla contiene una columna con el identificador del entrenador y la segunda contiene una lista con las criaturas capturadas por dicho entrenador. La llave de la tabla es el nombre del entrenador por lo que se muestra en negrita y cursiva.\n    Entrenador Pokemon     Ash [Pikachu, Caterpie, Charmander, …]   Misty [Staryu, Goldeen, Starmie, …]   Gary [Krabby, Nidoking, Arcanine, …]     Tabla 1: Entrenadores y sus Pokémon  Como se puede adivinar, es al menos extraño el manejar listas de elementos en una base de datos relacional. El utilizar ese tipo de estructuras en un atributo de una tabla puede producir dificultades al momento de implementar la base de datos. ¿Las colecciones pueden tener un tamaño máximo? ¿Cómo busco, agrego, ordeno o elimino eficientemente un elemento de la colección?\n¿Cómo se puede solucionar? La solución más ingenua, podría ser agregar más columnas, una para cada Pokémon atrapado. Esto supone nuevos problemas: ¿Cuántas columnas son suficientes? ¿Qué pasa con las columnas que no son utilizadas? ¿Cómo saber en cuál columna agregar la captura?\nPor lo general, la solución a este tipo de problemas es utilizar las llaves de ambas entidades relacionadas. En el caso del ejemplo, serían tanto el nombre del entrenador como el del Pokémon. El resultado puede apreciarse en la Tabla 2. Como un entrenador puede tener varios Pokémon tanto el nombre del entrenador como el nombre del Pokémon son la llave de la tabla. (Efectivamente esto restringe que un mismo entrenador capture dos pokémon del mismo nombre. ¿Cómo solucionar esto?)\n    Entrenador Pokemon     Ash Pikachu   Ash Caterpie   Ash Charmander   Misty Staryu   … …     Tabla 2: Entrenadores y sus Pokémon, un valor por celda  Cuando tenemos una relación como la de la Tabla 2, decimos que cada atributo tiene valores atómicos, es decir, valores que no son colecciones (conjuntos, listas, etc.). Este tipo de relaciones están en Primera Forma Normal.\nSupongamos que ahora que tenemos más información sobre el entrenador, sobre el Pokémon capturado y sobre la captura en sí. Por ejemplo, queremos almacenar la ciudad de la que el entrenador proviene, la salud y tipo del Pokémon capturado y la fecha y hora de la captura. Si seguimos con lo que veníamos haciendo en la Tabla 2, podríamos proponer un esquema como el que se ve en la Tabla 3. Podemos ver que la llave sigue siendo el nombre del entrenador y el del pokémon, sin embargo, al agregar también la fecha de captura a la llave podemos admitir que un entrenador capture más de un pokémon de la misma especie en momentos diferentes.\n    Entrenador Origen Pokemon Tipo HP Fecha Captura     Ash Pueblo Paleta Pikachu Eléctico 35 01-04-1997 10:20   Ash Pueblo Paleta Caterpie Insecto 45 02-04-1997 11:34   Ash Pueblo Paleta Charmander Fuego 39 05-04-1997 19:12   Misty Ciudad Celeste Staryu Agua 30 22-03-1995 09:44    Tabla 3: Entrenadores y sus Pokémon, con datos del entrenador, Pokémon y captura\n En el modelo de la Tabla 3, podemos encontrar varios problemas. Primero notamos que hay redundancia, pues cada vez que un entrenador capture un nuevo pokémon debemos repetir su ciudad de origen. Esto conlleva varias anomalías consigo, las cuales vamos a enumerar:\n Anomalía de Actualización: Si quisieramos modificar la ciudad de origen de un entrenador debemos asegurarnos de cambiarla correctamente en todas las filas que se refieren al entrenador. El no hacerlo, lleva a un estado inconsistente de la base de datos. Anomalía de Inserción: No podemos agregar un nuevo entrenadoral sistema si es que no ha capturado ningún pokémon aún. Esto pues la columna pokémon es parte de la llave y por lo tanto no admite valores nulos. Lo mismo con un pokémon, no tendremos registro de la especie o el tipo si nadie lo ha capturado. Anomalía de Borrado: Si un entrenador decide liberar a todos sus pokémon capturados, ¿qué hacemos con él? ¿Borramos todos sus datos?  ¿Cuál es el …","date":1540835003,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540835003,"objectID":"ed3af88e6ea1fd7cc0adb468bfef22b3","permalink":"http://www.sferrada.com/post/normal-forms/","publishdate":"2018-10-29T14:43:23-03:00","relpermalink":"/post/normal-forms/","section":"post","summary":"Al diseñar las relaciones que deben formar parte de un esquema relacional de bases de datos hay ciertos aspectos que se deben considerar de forma que se asegure que al agregar los datos en el esquema estos no presenten anomalías.","tags":["Databases","Relational Model","Database Normalization","Normal Forms"],"title":"Formas Pokenormales","type":"post"},{"authors":["Sebastián Ferrada Aliaga"],"categories":null,"content":"Este post provee de una introducción al concepto de llaves y dependencias funcionales en el campo de la teoría de las bases de datos relacionales. Está guiado por ejemplos, pero se presentan también algunas de las formalidades matemáticas. Si encuentras algún error o hay algo que no se logra entender muy bien, por favor deja un comentario debajo.\nLlaves En el modelo relacional trabajamos con conjuntos de tuplas que se almacenan en una relación dada. Como en un conjunto no se permiten elementos repetidos es necesario que cada tupla tenga una forma de identificarse y diferenciarse de las otras. La forma de identificar tuplas es utilizando el concepto de llave:\n Una llave es un conjunto de atributos de una relación, tal que ningún par de tuplas de la relación tiene los mismos valores en dichos atributos  Por ejemplo, consideremos los datos de la Tabla 1. Una llave trivial para cualquier relación es el conjunto de todos los atributos. En este caso {vino, año, cepa, presentación}. Una llave más pequeña puede ser {vino, cepa} o {año, presentación} (considerando solo estos datos). Dicho lo anterior, es conveniente recalcar que las llaves no deben seleccionarse condicionadas a los datos, sino que considerando la semántica de las relaciones y atributos.\n   Vino año cepa presentación     130 2018 Cabernet 750cc   Clos de Paine 2014 Cabernet 750cc   Santelena 2018 Sauvignon Blanc 2000cc    Ahora vamos con un par de definiciones. Una superllave es cualquier llave de una relación. Todas las mencionadas en el ejemplo son superllaves. Muchas veces se prefiere contar con una llave lo más pequeña posible, pues es necesario que podamos comparar rápidamente un par de tuplas para determinar si son idénticas o no. Para esto, introducimos la noción de llave candidata. Una llave candidata es una superllave tal que ningún subconjunto propio de ella también sea superllave, es decir, es minimal. Por ejemplo {vino, año, cepa, presentación} es una superllave pero no una llave candidata, pues {vino, cepa} también es una superllave. Esta última tampoco es llave candidata porque {nombre} también es superllave. Finalmente, {nombre} si es llave candidata, debido a que no hay subconjuntos propios posibles que sean también llave.\nUn atributo que pertenece a una llave candidata se llama atributo primo.\nPara terminar, una llave primaria es alguna de las llaves candidatas que se selecciona como la forma estándar de determinarla igualdad entre tuplas.\nEs necesario notar en este punto, que una relación puede entonces tener más de una llave candidata y estas llaves pueden tener distinta cantidad de atributos. Consideremos el siguiente esquema para almacenar datos de personas:\n Persona(RUT, nombre, fecha_hora_nacimiento, RUT_padre, RUT_madre)  Las llaves candidatas son {RUT} y {RUT_madre, fecha_hora_nacimiento}. 1 Como podemos apreciar, la segunda llave es minimal en el sentido de que no hay un subconjunto de esos atributos que también sea llave, por lo que es una llave candidata a pesar de tener una cantidad de atributos más grande que {RUT}. Sin embargo, probablemente se prefiera utilizar simplemente el RUT como llave primaria porque en este caso es lo más “natural” además que siempre es mejor tener menos elementos que comparar.\nDependencias Funcionales Dados dos conjuntos de atributos de un esquema relacional $X$ e $Y$, se dice que $Y$ depende funcionalmente de $X$ si para todo par de tuplas $t_1, t_2$ del esquema se cumple que si $t_1[X]=t_2[X]$ entonces $t_1[Y]=t_2[Y]$. 2 Es decir, para cada valor de $X$ hay un único valor de $Y$ posible. Cuando $X$ determina funcionalmente a Y se escribe $X \\rightarrow Y$. Cuando $Y$ es un subconjunto de $X$ se dice que la dependencia funcional es trivial.\nConocer las dependencias funcionales de un esquema es importante para el diseño relacional, pues nos ayudan a determinar si las relaciones propuestas por un modelo pueden o no presentar anomalías.\nInicialmente, se sabe que una llave candidata determina funcionalmente a todos los atributos. Sin embargo, es posible que otros atributos se determinen entre ellos. Supongamos que contamos con la siguiente información de contacto:\n Contacto(RUT, email, dirección, comuna, región)  Claramente el RUT e email son llaves candidatas y, por lo tanto, determinan funcionalmente a todo el resto de los atributos. Por otro lado también sabemos que una comuna se encuentra en una sola región y entonces dos contactos de la misma comuna van a estar necesariamente en la misma región. Entonces sabemos que {comuna} $\\rightarrow$ {región}. Como los nombres de calles pueden repetirse entre comunas, podemos descartar la dependencia {dirección} $\\rightarrow$ {comuna}.\nCuando un esquema cuenta con varias dependencias funcionales, podemos razonar lógicamente sobre ellas y concluir otras dependencias nuevas y coherentes con el esquema. Existe un conjunto de reglas de razonamiento que nos permite obtener el conjunto completo de dependencias funcionales de un esquema, a partir de un conjunto …","date":1540831403,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540831403,"objectID":"31a0b3a0ecc5cfd6fadcf1ea2d488d2d","permalink":"http://www.sferrada.com/post/functional-dependencies/","publishdate":"2018-10-29T13:43:23-03:00","relpermalink":"/post/functional-dependencies/","section":"post","summary":"Este post provee de una introducción al concepto de llaves y dependencias funcionales en el campo de la teoría de las bases de datos relacionales. Está guiado por ejemplos, pero se presentan también algunas de las formalidades matemáticas.","tags":["Databases","Relational Design","Functional Dependencies"],"title":"Llaves y Dependencias Funcionales","type":"post"},{"authors":null,"categories":null,"content":"","date":1538481601,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538481601,"objectID":"b4cfd73ae04ae3e920a62876c887f8a1","permalink":"http://www.sferrada.com/talk/clei-cltm18/","publishdate":"2018-10-02T09:00:01-03:00","relpermalink":"/talk/clei-cltm18/","section":"talk","summary":"IMGpedia is a large-scale linked dataset that incorporates visual information of the images from the Wikimedia Commons dataset: it brings together descriptors of the visual content of 15 million images, 450 million visual-similarity relations between those images, links to image metadata from DBpedia Commons, and links to the DBpedia resources associated with individual images. In this paper we describe the creation of the IMGpedia dataset, provide an overview of its schema and statistics of its contents, offer example queries that combine semantic and visual information of images, and discuss other envisaged use-cases for the dataset","tags":["Masters Thesis","Visuo-semantic Queries","Web Image Retrieval","Semantic Web","IMGpedia"],"title":"IMGpedia at CLTM-CLEI","type":"talk"},{"authors":["Sebastián Ferrada","Benjamin Bustos","Nora Reyes"],"categories":null,"content":"","date":1526860800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526860800,"objectID":"262445c5dbc50cbcc2d32168229f3562","permalink":"http://www.sferrada.com/publication/ferrada-simple-2018/","publishdate":"2018-05-21T00:00:00Z","relpermalink":"/publication/ferrada-simple-2018/","section":"publication","summary":"The use of the join operator in metric spaces leads to what is known as a similarity join, where objects of two datasets are paired if they are  somehow  similar. We propose an heuristic that solves the 1-NN self-similarity join, that is, a similarity join of a dataset with itself, that brings together each element with its nearest neighbor within the same dataset. Solving the problem using a simple brute-force algorithm requires $O(n^2)$ distance calculations, since it requires to compare every element against all others. We propose a simple divide-and-conquer algorithm that gives an approximated solution for the self-similarity join that computes only $O(n^\\frac{3}{2}) $ distances. We show how the algorithm can be easily modified in order to improve the precision up to 31% (i.e., the percentage of correctly found 1-NNs) and such that 79% of the results are within the 10-NN, with no significant extra distance computations. We present how the algorithm can be executed in parallel and prove that using $\\Theta(\\sqrt{n})$ processors, the total execution takes linear time. We end discussing ways in which the algorithm can be improved in the future.","tags":null,"title":"A Simple, Efficient, Parallelizable Algorithm for Approximated Nearest Neighbors.","type":"publication"},{"authors":["Sebastián Ferrada","Nicolás Bravo","Benjamin Bustos","Aidan Hogan"],"categories":null,"content":"","date":1524268800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524268800,"objectID":"b4c278e9b824e0530ec82c9fc239427f","permalink":"http://www.sferrada.com/publication/ferrada-querying-2018/","publishdate":"2018-04-21T00:00:00Z","relpermalink":"/publication/ferrada-querying-2018/","section":"publication","summary":"Despite its importance to the Web, multimedia content is often neglected when building and designing knowledge-bases: though descriptive metadata and links are often provided for images, video, etc., the multimedia content itself is often treated as opaque and is rarely analysed. IMGpedia is an effort to bring together the images of Wikimedia Commons (including visual information), and relevant knowledge-bases such as Wikidata and DBpedia. The result is a knowledge-base that incorporates similarity relations between the images based on visual descriptors, as well as links to the resources of Wikidata and DBpedia that relate to the image. Using the IMGpedia SPARQL endpoint, it is then possible to perform visuo-semantic queries, combining the semantic facts extracted from the external resources and the similarity relations of the images. This paper presents a new web interface to browse and explore the dataset of IMGpedia in a more friendly manner, as well as new visuo-semantic queries that can be answered using 6 million recently added links from IMGpedia to Wikidata. We also discuss future directions we foresee for the IMGpedia project.","tags":["IMGpedia","Multimedia","SPARQL","Visuo-semantic Queries","Wikidata"],"title":"Querying Wikimedia Images using Wikidata Facts","type":"publication"},{"authors":["Sebastián Ferrada Aliaga"],"categories":null,"content":"IMGpedia es una base de datos enlazados que extrae características visuales a las imágenes de Wikimedia Commons y que provee enlaces a DBpedia al contexto de la imagen, permitiendo así realizar consultas visuo-semánticas. IMGpedia fue mi tesis de magíster guiada por Benjamin Bustos y Aidan Hogan. Muy probablemente será mi tesis de doctorado también. En este post les voy a contar de qué se trata IMGpedia y mi experiencia compartiendo este trabajo en ISWC 2017 en Viena, Austria.\nLa idea que motiva el trabajo es incluir fuertemente el análisis de contenido multimedia en la Web de Datos, tomando en cuenta que la información multimedia es parte fundamental para la experiencia de los usuarios en la Web. IMGpedia nos permitiría poder hacer consultas de similitud visual entre imágenes, obtener imágenes que cumplan un cierto predicado y mezclar ambos enfoques, lo que llamamos una consulta visuo-semántica. Por ejemplo, nos permitiría responder la siguiente consulta: dada una imagen de la catedral de Cusco, obtener imágenes similares de catedrales europeas.\nPara lograr el objetivo, debemos seguir la siguiente metodología:\n Obtener las imágenes para procesarlas localmente. Calcular los descriptores visuales (vectores de características) de las imágenes. Obtener estáticamente relaciones de similitud entre las imágenes. Enlazar las imágenes con otras fuentes de información (DBpedia, Wikidata, Freebase). Publicar todo como RDF, a través de un terminal SPARQL.  Descargar los 14,7 millones de imágenes nos tomó 40 días con múltiples conexiones. El tamaño total de las imágenes es de 22 Terabytes. Una vez descargadas, calculamos los descriptores visuales, en particular calculamos histogramas de grises, histogramas de la orientación de los bordes y un descriptor basado en color. Puedes encontrar más detalles sobre los descriptores y código visitando el GitHub del proyecto (en inglés).\nComo se puede ver en la Figura 1, nuestro objetivo es enlazar las imágenes que sean visualmente similares. Para hacer esto, tomamos un descriptor y encontramos sus 10 vecinos más cercanos, pues asumimos que si dos vectores están cerca, es por que son similares. Esta decisión de tomar los k vecinos más cercanos ha generado mucha discusión, pero si están interesados, hay una reflexión al respecto al final del post.\n**Figura 1:** Similitud entre imágenes Luego, necesitamos obtener contexto de la imagen: saber qué es, cómo se llama lo que aparece en ella o con qué está relacionada. Para esto, usamos un dump de la Wikipedia en inglés para reunir los pares (nombre_img, nombre_wiki) de modo que la imagen aparece en la wiki. Entonces enlazamos la imagen con el recurso de DBpedia relacionado al articulo de Wikipedia correspondiente. Por ahora, nada nos asegura que la imagen realmente contenga a la entidad con la que está relacionada, pero sí podemos decir que la imagen está asociada a la entidad de alguna forma u otra. En la Figura 2 se muestra lo que se pretende hacer, por ejemplo si una imagen aparece en la wiki de Quentin Tarantino, entonces enlazamos la imagen con el recurso de Tarantino en DBpedia.\n**Figura 2:** Obtener contexto de la imagen Finalmente, publicamos todo en formato RDF que puede ser consultado a través de un terminal público de SPARQL. Los datos tienen un cierto esquema para modelar clases y atributos que puede ser encontrado aquí En este terminal, podemos hacer por ejemplo las siguientes consultas:\n Obtener todas las imágenes similares a la foto de Hopsten Marktplatz:  SELECT DISTINCT ?Target WHERE { im:Hopsten_Marktplatz_3.jpg imo:similar ?Target . } **Figura 3:** Resultados de la consulta a  Obtener imágenes de las pinturas hechas el siglo XVI, que están en exposición en el Louvre (ojo que también podemos obtener otros datos como el nombre de la pintura, quién la pintó, etc.):  SELECT DISTINCT ?url ?label WHERE { SERVICE \u0026lt;https://dbpedia.org/sparql\u0026gt; { ?res a yago:Wikicat16th-centuryPaintings ; dcterms:subject dbc:Paintings_of_the_Louvre ; rdfs:label ?label . FILTER(LANG(?label)=\u0026#34;en\u0026#34;) } ?img imo:associatedWith ?res ; imo:fileURL ?url . } **Figura 4:** Resultados de la consulta b  Finalmente podemos combinar ambos tipos de preguntas en una consulta que llamamos visuo-semántica, por ejemplo entre todas las imágenes de catedrales europeas, obtener imágenes similares que sean museos:  SELECT DISTINCT ?source ?target WHERE { SERVICE \u0026lt;https://dbpedia.org/sparql\u0026gt; { ?sres dcterms:subject/skos:broader* dbc:Roman_Catholic_cathedrals_in_Europe } ?source imo:associatedWith ?sres ; imo:similar ?target . ?target imo:associatedWith ?tres ; imo:fileURL ?urlt . SERVICE \u0026lt;https://dbpedia.org/sparql\u0026gt; { ?tres dcterms:subject ?subject . FILTER(CONTAINS(STR(?sub), “Museum”))} } **Figura 5:** Resultados de la consulta c Tras mi defensa del Magister, este trabajo fue aceptado en el track de recursos de la 16ta Conferencia Internacional de la Web Semántica (ISWC) y viajé a Viena a presentarlo, puedes encontrar las diapositivas aquí. También participamos en la …","date":1509054203,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509054203,"objectID":"9f066239c846b24ea788dcd544f27706","permalink":"http://www.sferrada.com/post/imgpedia-iswc/","publishdate":"2017-10-26T18:43:23-03:00","relpermalink":"/post/imgpedia-iswc/","section":"post","summary":"IMGpedia es una base de datos enlazados que extrae características visuales a las imágenes de Wikimedia Commons y que provee enlaces a DBpedia al contexto de la imagen, permitiendo así realizar consultas visuo-semánticas.","tags":["IMGpedia","ISWC","Linked Data","Multimedia"],"title":"IMGpedia, la importancia de incluir multimedia en la Web de Datos","type":"post"},{"authors":null,"categories":null,"content":"","date":1508760001,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508760001,"objectID":"f3ed7bac4a98503786eea4a181cfd579","permalink":"http://www.sferrada.com/talk/imgpediaiswc17/","publishdate":"2017-10-23T14:00:01+02:00","relpermalink":"/talk/imgpediaiswc17/","section":"talk","summary":"IMGpedia is a large-scale linked dataset that incorporates visual information of the images from the Wikimedia Commons dataset: it brings together descriptors of the visual content of 15 million images, 450 million visual-similarity relations between those images, links to image metadata from DBpedia Commons, and links to the DBpedia resources associated with individual images. In this paper we describe the creation of the IMGpedia dataset, provide an overview of its schema and statistics of its contents, offer example queries that combine semantic and visual information of images, and discuss other envisaged use-cases for the dataset","tags":[],"title":"IMGpedia at ISWC","type":"talk"},{"authors":["Sebastián Ferrada","Benjamin Bustos","and Aidan Hogan"],"categories":null,"content":"","date":1508716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508716800,"objectID":"53af5ebea5f45ea5fff6614e5e2aca8d","permalink":"http://www.sferrada.com/publication/ferrada-imgpedia-2017/","publishdate":"2017-10-23T00:00:00Z","relpermalink":"/publication/ferrada-imgpedia-2017/","section":"publication","summary":"IMGpedia is a large-scale linked dataset that incorporates visual information of the images from the Wikimedia Commons dataset: it brings together descriptors of the visual content of 15 million images, 450 million visual-similarity relations between those images, links to image metadata from DBpedia Commons, and links to the DBpedia resources associated with individual images. In this paper we describe the creation of the IMGpedia dataset, provide an overview of its schema and statistics of its contents, offer example queries that combine semantic and visual information of images, and discuss other envisaged use-cases for the dataset.","tags":["IMGpedia","Multimedia","SPARQL","Visuo-semantic Queries"],"title":"IMGpedia: a linked dataset with content-based analysis of Wikimedia images","type":"publication"},{"authors":null,"categories":null,"content":"","date":1499432400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499432400,"objectID":"90d74fba3d87c1b835ed65a9448eb140","permalink":"http://www.sferrada.com/talk/mscdefense/","publishdate":"2017-07-07T10:00:00-03:00","relpermalink":"/talk/mscdefense/","section":"talk","summary":"Since its beginning, the Web of Data has been focused on the curation and production of machine-understandable representations of the textual information on the Web, being multimedia information mostly disregarded. In this talk, we present IMGpedia: a novel knowledge-base that automatically extracts visual features from Wikimedia Commons images in order to enable combining visual similarity queries amongst images with semantic filters.","tags":[],"title":"IMGpedia: a Large-scale Knowledge-base to perform Visuo-semantic Queries over Wikimedia Commons Images","type":"talk"},{"authors":null,"categories":null,"content":"","date":1496689200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496689200,"objectID":"1c04814c25e43ece6e7f8ed7ffc5d0a0","permalink":"http://www.sferrada.com/talk/amw17-poster/","publishdate":"2017-06-05T17:00:00-02:00","relpermalink":"/talk/amw17-poster/","section":"talk","summary":"","tags":[],"title":"AMW 2017 School - Poster Session","type":"talk"},{"authors":["Sebastián Ferrada","Benjamin Bustos","Aidan Hogan"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"f161a525997dbc24e9f66a6a0838e866","permalink":"http://www.sferrada.com/publication/ferrada-answering-2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/ferrada-answering-2017/","section":"publication","summary":"IMGpedia is a linked dataset that provides a public SPARQL endpoint where users can answer queries that combine the visual similarity of images from Wikimedia Commons and semantic information from existing knowledge-bases. Our demo will show example queries that capture the potential of the current data stored in IMGpedia. We also plan to discuss potential use-cases for the dataset and ways in which we can improve the quality of the information it captures and the expressiveness of the queries.","tags":["IMGpedia","Multimedia","SPARQL","Visuo-semantic Queries"],"title":"Answering Visuo-Semantic Queries with IMGpedia.","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"52a607107ddc8444c504f90bd54ea709","permalink":"http://www.sferrada.com/project/constitucion-abierta/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/constitucion-abierta/","section":"project","summary":"Visualizing the results of the Chilean constitutional process.","tags":["Visualization"],"title":"Constitución Abierta","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"5bd4a702defc0711e3d7e45c26069847","permalink":"http://www.sferrada.com/project/imgpedia-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/imgpedia-project/","section":"project","summary":"Combining visual and semantic queries on the Web.","tags":["Multimedia","Linked Data"],"title":"IMGpedia project","type":"project"},{"authors":["Sebastián Ferrada","Benjamin Bustos","Aidan Hogan"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"48a95ca009c747f25ae87212ac7cae5d","permalink":"http://www.sferrada.com/publication/ferrada-imgpedia-2016/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/ferrada-imgpedia-2016/","section":"publication","summary":"Linked Data rarely takes into account multimedia content, which forms a central part of the Web. To explore the combination of Linked Data and multimedia, we are developing IMGpedia: we compute content-based descriptors for images used in Wikipedia articles and subsequently propose to link these descriptions with legacy encyclopaedic knowledge-bases such as DBpedia and Wikidata. On top of this extended knowledge-base, our goal is to consider a unified query system that accesses both the encyclopaedic data and the image data. We could also consider enhancing the encyclopaedic knowledge based on rules applied to co-occurring entities in images, or content-based analysis, for example. Abstracting away from IMGpedia, we explore generic methods by which the content of images on the Web can be described in a standard way and can be considered as first-class citizens on the Web of Data, allowing, for example, for combining structured queries with image similarity search. This short paper thus describes ongoing work on IMGpedia, with focus on image descriptors.","tags":["IMGpedia","Multimedia","SPARQL","Visuo-semantic Queries"],"title":"IMGpedia: Enriching the Web of Data with Image Content Analysis.","type":"publication"}]